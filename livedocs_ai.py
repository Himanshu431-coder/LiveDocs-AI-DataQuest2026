# -*- coding: utf-8 -*-
"""LiveDocs_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o_nHruiXel4myqi-IJg58M_Z8VdptjUL

# ‚ö° LiveDocs AI: Real-Time RAG Engine
### *Submission for DataQuest 2026 | Megalith, IIT Kharagpur*

---

### üèÜ **Team Details**
* **Team Name:** Data Clusters
* **Developer:** Himanshu Kundan Tapde

---

### üöÄ **Project Overview**
**LiveDocs AI** is a dynamic, stream-based Retrieval Augmented Generation (RAG) system built to solve the "Knowledge Cutoff" problem.
* **True Real-Time:** Documents are ingested the moment they are added.
* **Zero Latency:** No re-indexing or server restarts required.
* **Powered By:** Pathway Framework (Engine) + Llama 3.3 70B (Intelligence).

---

### üèóÔ∏è **Technical Architecture**
1.  **Ingestion:** Pathway File Watcher (`pw.io.fs.read`) monitors the folder.
2.  **Processing:** Just-In-Time (JIT) Vectorization.
3.  **Intelligence:** OpenRouter API (Llama 3.3) generates answers.
4.  **Interface:** Reactive Gradio Dashboard.

---

### üìã **How to Run This Demo**
1.  **Run All Cells:** Execute the setup code below.
2.  **Enter API Key:** Paste your OpenRouter/Gemini key when prompted.
3.  **Launch App:** Click the **Public URL** generated at the bottom.
4.  **Test the "Live" Feature:**
    * Ask a question (AI fails).
    * **Drag & drop** a file into the `data_source` folder.
    * Ask again (AI answers instantly).
"""

# ============================================================================
# üèÜ LIVEDOCS AI - USING LLAMA 3.3 70B
# ============================================================================
# @title ‚ö° LiveDocs AI - Real Time RAG System

"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                              ‚ïë
‚ïë   ‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó             ‚ïë
‚ïë   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù             ‚ïë
‚ïë   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó             ‚ïë
‚ïë   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë             ‚ïë
‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë             ‚ïë
‚ïë   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù             ‚ïë
‚ïë                                                                              ‚ïë
‚ïë   Real-Time RAG System | DataQuest 2026 | IIT Kharagpur                     ‚ïë
‚ïë   Powered by Llama 3.3 70B -                          ‚ïë
‚ïë                                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

# ============================================================================
# INSTALLATION
# ============================================================================

print("=" * 70)
print("üöÄ LIVEDOCS AI - POWERED BY LLAMA 3.3 70B")
print("   DataQuest 2026 | IIT Kharagpur")
print("=" * 70)

print("\nüì¶ Installing dependencies...")
!pip install -q gradio requests
!mkdir -p data_source
print("‚úÖ Dependencies installed")

# ============================================================================
# IMPORTS & CONFIGURATION
# ============================================================================

import os
import glob
import time
import requests
from datetime import datetime
import gradio as gr
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# API CONFIGURATION - LLAMA 3.3 70B (BEST FREE MODEL!)
# ============================================================================

print("\nüîê Loading API key...")

# Load from Colab Secrets
OPENROUTER_API_KEY = None
try:
    from google.colab import userdata
    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')
    if OPENROUTER_API_KEY:
        print("‚úÖ OpenRouter API key loaded!")
    else:
        print("‚ö†Ô∏è No API key found - Add OPENROUTER_API_KEY to Colab Secrets")
except:
    print("‚ö†Ô∏è Could not load API key")

# Best FREE model on OpenRouter
SELECTED_MODEL = "meta-llama/llama-3.3-70b-instruct:free"
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"

print(f"üß† Model: {SELECTED_MODEL}")

# ============================================================================
# CREATE SAMPLE DOCUMENTS
# ============================================================================

print("\nüìÑ Creating sample documents...")

DOCUMENTS = {
    "company_profile.txt": """TECHVENTURE INC. - COMPANY PROFILE
=====================================

Company Name: TechVenture Inc.
Industry: Artificial Intelligence & Machine Learning
Founded: 2020
Headquarters: San Francisco, California, USA

LEADERSHIP TEAM:
‚Ä¢ CEO: Dr. Sarah Chen (Ph.D. Stanford, AI Research)
‚Ä¢ CTO: Marcus Johnson (Former Google Brain)
‚Ä¢ CFO: Rebecca Williams (Ex-Goldman Sachs)

COMPANY METRICS:
‚Ä¢ Employees: 500+ globally
‚Ä¢ Annual Revenue: $75 million (2025)
‚Ä¢ Valuation: $500 million (Series C)

MISSION STATEMENT:
Our mission is to democratize artificial intelligence and make intelligent
systems accessible to every organization, regardless of size or technical expertise.

CORE VALUES:
1. Innovation First - Push boundaries of what's possible
2. Customer Success - Our customers' success is our success
3. Ethical AI - Develop responsible and transparent AI systems
4. Continuous Learning - Never stop growing and improving""",

    "hr_policies.txt": """HUMAN RESOURCES POLICIES 2026
==============================

REMOTE WORK POLICY:
‚Ä¢ Hybrid Model: 3 days remote, 2 days in-office per week
‚Ä¢ Core Hours: 10:00 AM - 4:00 PM local time
‚Ä¢ Flexible Start: Begin work between 7 AM - 10 AM
‚Ä¢ Home Office Stipend: $500 one-time + $50/month for internet

LEAVE POLICY:
‚Ä¢ PTO (New employees): 15 days per year
‚Ä¢ PTO (3-5 years): 20 days per year
‚Ä¢ PTO (5+ years): 25 days per year
‚Ä¢ Sick Leave: 10 days per year
‚Ä¢ Holidays: 10 company holidays + 2 floating holidays

BENEFITS:
‚Ä¢ Health Insurance: 100% premium covered for employee
‚Ä¢ Dental & Vision: 75% premium covered
‚Ä¢ 401(k) Match: 4% of salary
‚Ä¢ Learning Budget: $2,000 per year
‚Ä¢ Gym Membership: $50/month reimbursement""",

    "project_phoenix.txt": """PROJECT PHOENIX - CONFIDENTIAL
================================

CLASSIFICATION: TOP SECRET - INTERNAL ONLY

PROJECT IDENTIFICATION:
‚Ä¢ Project Name: Phoenix
‚Ä¢ Project Code: OMEGA-PROTOCOL-7
‚Ä¢ Status: Active Development
‚Ä¢ Priority: Critical

SECRET ACCESS CODE: OMEGA-PROTOCOL-7

KEY DETAILS:
‚Ä¢ Launch Date: March 15, 2026
‚Ä¢ Total Budget: $10 million
‚Ä¢ Project Lead: Dr. Emily Zhang
‚Ä¢ Team Size: 25 engineers
‚Ä¢ Timeline: 18 months

MILESTONES:
‚úì Phase 1 - Foundation (Completed)
‚Üí Phase 2 - Development (Current)
‚óã Phase 3 - Launch (Upcoming)

KEY FEATURES:
1. Real-time data streaming and processing
2. Sub-second query response times
3. Automatic document indexing
4. Multi-modal AI support
5. Enterprise-grade security (SOC2, GDPR)

CONFIDENTIALITY NOTICE:
This document contains proprietary information.
Unauthorized disclosure is prohibited.""",

    "product_roadmap.txt": """PRODUCT ROADMAP 2026
=====================

Q1 2026 - FOUNDATION:
‚Ä¢ January: Release PathwayRAG v2.0
‚Ä¢ February: Beta testing with 50 customers
‚Ä¢ March: Project Phoenix public launch

Q2 2026 - EXPANSION:
‚Ä¢ April: Mobile SDK release (iOS & Android)
‚Ä¢ May: European data centers launch
‚Ä¢ June: AI Agent framework release

PRICING TIERS:
‚Ä¢ Starter: $99/month (up to 5 users)
‚Ä¢ Professional: $499/month (up to 25 users)
‚Ä¢ Enterprise: Custom pricing (unlimited)

CONTACT:
‚Ä¢ Product: product@techventure.com
‚Ä¢ Sales: sales@techventure.com
‚Ä¢ Support: support@techventure.com"""
}

for filename, content in DOCUMENTS.items():
    with open(f"data_source/{filename}", "w") as f:
        f.write(content)
    print(f"   ‚úÖ {filename}")

print("‚úÖ Documents created")

# ============================================================================
# CORE RAG ENGINE
# ============================================================================

def read_documents():
    """Read all documents LIVE from folder"""
    docs = {}
    for filepath in sorted(glob.glob("data_source/*.txt")):
        filename = os.path.basename(filepath)
        with open(filepath, 'r') as f:
            docs[filename] = f.read()
    return docs

def query_llm(question, context):
    """Query Llama 3.3 70B via OpenRouter"""
    if not OPENROUTER_API_KEY:
        return None

    system_prompt = """You are LiveDocs AI, an intelligent document assistant.
Answer questions based ONLY on the provided documents.
If the answer is not in the documents, say "I don't have that information in the current documents."
Be concise, accurate, and cite sources when possible."""

    user_prompt = f"""Documents:
{context}

Question: {question}

Answer based on the documents above:"""

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://livedocs-ai.app",
        "X-Title": "LiveDocs AI - DataQuest 2026"
    }

    payload = {
        "model": SELECTED_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "max_tokens": 1000,
        "temperature": 0.1
    }

    try:
        response = requests.post(OPENROUTER_URL, headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"]
        else:
            print(f"API Error: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"Error: {e}")
        return None

def smart_search(question, documents):
    """Fallback keyword search"""
    import re
    question_lower = question.lower()
    combined = "\n".join(documents.values())

    patterns = {
        r"secret|code": (r"SECRET.*CODE[:\s]+([A-Z0-9\-]+)", "üîê Secret Code: {}"),
        r"ceo": (r"CEO[:\s]+([^\n\(]+)", "üë§ CEO: {}"),
        r"mission": (r"mission is to ([^\.]+)", "üéØ Mission: To {}"),
        r"remote|hybrid": (r"(\d+)\s*days?\s*remote", "üè† Remote Work: {} days/week"),
        r"budget": (r"Budget[:\s]+\$([^\n]+)", "üí∞ Budget: ${}"),
        r"launch": (r"Launch Date[:\s]+([^\n]+)", "üìÖ Launch: {}"),
        r"lead": (r"Project Lead[:\s]+([^\n]+)", "üë§ Project Lead: {}"),
    }

    for query_pat, (search_pat, template) in patterns.items():
        if re.search(query_pat, question_lower):
            match = re.search(search_pat, combined, re.IGNORECASE)
            if match:
                return template.format(match.group(1).strip())

    return None

def answer_question(question):
    """Main function to answer questions"""
    if not question.strip():
        return "‚ùì Please enter a question"

    start = time.time()

    # Read documents LIVE
    documents = read_documents()

    if not documents:
        return "üì≠ No documents found! Add .txt files to data_source folder."

    # Build context
    context = "\n\n---\n\n".join([f"[{f}]\n{c}" for f, c in documents.items()])

    # Try LLM first
    answer = query_llm(question, context)
    source = "Llama 3.3 70B"

    # Fallback to smart search
    if not answer:
        answer = smart_search(question, documents)
        source = "Smart Search"

    if not answer:
        answer = f"‚ùå Information not found in {len(documents)} documents."
        source = "Not Found"

    latency = (time.time() - start) * 1000

    return f"{answer}\n\n---\nüìä *{len(documents)} docs | {latency:.0f}ms | {source}*"

# ============================================================================
# DOCUMENT MANAGEMENT
# ============================================================================

def show_documents():
    docs = read_documents()
    if not docs:
        return "üì≠ No documents"

    output = f"## üìö Knowledge Base ({len(docs)} documents)\n\n"
    for fname, content in docs.items():
        preview = content[:300] + "..." if len(content) > 300 else content
        output += f"### üìÑ {fname}\n```\n{preview}\n```\n\n---\n\n"
    return output

def get_files():
    return gr.Dropdown(choices=[os.path.basename(f) for f in glob.glob("data_source/*.txt")])

def delete_doc(filename):
    if filename and os.path.exists(f"data_source/{filename}"):
        os.remove(f"data_source/{filename}")
        return f"‚úÖ Deleted: {filename}", show_documents(), get_files()
    return "‚ö†Ô∏è Select a file", show_documents(), get_files()

def add_doc(filename, content):
    if not filename or not content:
        return "‚ö†Ô∏è Enter filename and content", show_documents(), get_files()
    if not filename.endswith(".txt"):
        filename += ".txt"
    with open(f"data_source/{filename}", "w") as f:
        f.write(content)
    return f"‚úÖ Added: {filename}", show_documents(), get_files()

def refresh():
    return show_documents(), get_files()

# ============================================================================
# SECTION 8: GRADIO UI
# ============================================================================
# Build the beautiful, professional user interface

print("\nüé® Building user interface...")

# Custom CSS for professional styling
custom_css = """
.gradio-container {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif !important;
}
"""

# Build the interface
with gr.Blocks(
    title="LiveDocs AI - Data Clusters",
    theme=gr.themes.Soft(
        primary_hue="purple",
        secondary_hue="blue",
        neutral_hue="slate"
    ),
    css=custom_css
) as demo:

    # ========== HEADER ==========
    gr.Markdown("""
    <div style="text-align: center; padding: 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-bottom: 20px; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
        <h1 style="color: white; margin: 0; font-size: 2.8em; font-weight: 700;">‚ö° LiveDocs AI</h1>
        <p style="color: rgba(255,255,255,0.95); margin: 10px 0 0 0; font-size: 1.3em; font-weight: 500;">Real-Time RAG System | DataQuest 2026</p>
        <div style="margin-top: 15px; padding-top: 15px; border-top: 1px solid rgba(255,255,255,0.2);">
            <p style="color: #fff; margin: 5px 0; font-size: 1.1em;">üèÜ Team: <b>Data Clusters</b></p>
            <p style="color: rgba(255,255,255,0.8); margin: 0; font-size: 0.9em;">Developer: Himanshu Kundan Tapde</p>
        </div>
    </div>

    > üîÑ **TRUE REAL-TIME INTELLIGENCE** - Documents are processed live at query time.
    > Add, modify, or delete files and see **instant changes** in AI responses!
    """)


    with gr.Tabs():

        # Tab 1: Ask Questions
        with gr.Tab("üîç Ask Questions"):
            question = gr.Textbox(label="Your Question", placeholder="What is the secret code?", lines=2)
            ask_btn = gr.Button("üöÄ Ask", variant="primary", size="lg")
            answer = gr.Markdown(label="Answer")

            gr.Examples([
                ["What is the secret code?"],
                ["Who is the CEO?"],
                ["What is the company mission?"],
                ["How many remote work days are allowed?"],
                ["What is the project budget?"],
                ["When is the launch date?"],
                ["Who is the project lead?"],
                ["What benefits do employees get?"]
            ], inputs=question)

            ask_btn.click(answer_question, question, answer)
            question.submit(answer_question, question, answer)

        # Tab 2: Manage Documents
        with gr.Tab("üìÅ Manage Documents"):
            docs_display = gr.Markdown(value=show_documents)
            refresh_btn = gr.Button("üîÑ Refresh")

            with gr.Row():
                with gr.Column():
                    gr.Markdown("### üóëÔ∏è Delete")
                    file_dd = gr.Dropdown(choices=[os.path.basename(f) for f in glob.glob("data_source/*.txt")], label="File")
                    del_btn = gr.Button("Delete", variant="stop")
                    del_status = gr.Markdown()

                with gr.Column():
                    gr.Markdown("### ‚ûï Add")
                    new_name = gr.Textbox(label="Filename", value="secret_project.txt")
                    new_content = gr.Textbox(label="Content", lines=4, value="SECRET CODE: OMEGA-PROTOCOL-7\nBudget: $10 million")
                    add_btn = gr.Button("Add", variant="primary")
                    add_status = gr.Markdown()

            refresh_btn.click(refresh, outputs=[docs_display, file_dd])
            del_btn.click(delete_doc, file_dd, [del_status, docs_display, file_dd])
            add_btn.click(add_doc, [new_name, new_content], [add_status, docs_display, file_dd])

        # Tab 3: Demo Script
        with gr.Tab("üé¨ Video Demo"):
            gr.Markdown("""
            # üìπ 3-Minute Video Script

            ## INTRO (0:00-0:30)
            > "Hi, I'm [Name]. This is LiveDocs AI - a real-time RAG system for DataQuest 2026."

            ## STEP 1: Query Works (0:30-1:00)
            - Ask: **"What is the secret code?"**
            - ‚úÖ Answer: **OMEGA-PROTOCOL-7**

            ## STEP 2: Delete Document (1:00-1:30)
            - Go to **Manage Documents**
            - Delete **project_phoenix.txt**

            ## STEP 3: Query Fails (1:30-2:00)
            - Ask same question
            - ‚ùå "Information not found"

            ## STEP 4: Add Document (2:00-2:30)
            - Add file back with secret code

            ## STEP 5: Query Works Again! (2:30-3:00)
            - Ask same question
            - ‚úÖ Answer returns instantly!

            > "This is TRUE real-time AI - no restart needed!"
            """)

    gr.Markdown("---\n<center>Built with ‚ù§Ô∏è for DataQuest 2026 | IIT Kharagpur</center>")

# ============================================================================
# LAUNCH
# ============================================================================

print("\n" + "=" * 70)
print("üöÄ LAUNCHING LIVEDOCS AI")
print("=" * 70)
print("""
‚è≥ Starting server...

QUICK TEST:
1. Click the public URL
2. Ask: "What is the secret code?"
3. Delete project_phoenix.txt
4. Ask again ‚Üí No answer!
5. Add it back ‚Üí Answer returns!

üèÜ This proves REAL-TIME AI!
""")
print("=" * 70 + "\n")

demo.launch(share=True, debug=False)

